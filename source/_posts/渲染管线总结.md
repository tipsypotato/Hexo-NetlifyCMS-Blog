---
excerpt: 渲染管线的一般结构，Forward/Deferred/Tile-Based/Forward+ Rendering
abbrlink: eeea93b8
title: 渲染管线总结
date: 2022-08-26 07:06:06
tags:
  - Rendering
categories:
  - Rendering
comments: true
mathjax: true
---
# Overview

## Draw Call

 Draw Call 的本身含义就是 CPU 调用图像编程接口，比如 OpenGL 中的 glDrawElements，一般由 Draw Call 引起的性能瓶颈在于 CPU 和 GPU 的通信。CPU 和 GPU 通过**命令缓冲区**进行通信，CPU 向其中添加命令(改变渲染状态，渲染模型X)，GPU 从其中读命令然后执行。

- 为什么 draw call 多了会影响性能？可以类比复制很多个小文件和一个大文件
- 如何减少 draw call 的次数？可以进行 batching，比如可以在 CPU 中将场景中静态的大地、石头等静态物体进行一次合并。避免使用大量很小的 mesh，一定要使用的时候，尽量考虑进行 batching；避免使用过多材质，尽量不同 mesh 共用一个材质。

 <img src=/images/pipeline-summary/Untitled.png width="80%" height="80%">

## 渲染流水线的三个阶段

- 应用阶段：输出顶点数据 (位置、纹理坐标、法线)
    
    开发者布置 scene，通常是在 CPU 端进行处理，包括**碰撞检测、动画物理模拟、视椎体剔除、遮挡剔除**，通过视椎体剔除和遮挡剔除，可以减少对最终图像没有贡献的部分，降低 CPU 与 GPU 传输的数据量，也大大减少了 GPU 的负载。（貌似可以利用 compute shader 进行视椎体剔除和遮挡剔除，待补充）
    
- 几何阶段：输出屏幕空间的的顶点信息
    
    **Vertex顶点着色器**(完全可编程)：CPU 将顶点属性传到 GPU 中，每个顶点都会过一遍顶点着色器，且不能创建、销毁顶点，无法得到其他顶点的信息。因而顶点之间可以并行处理，速度快。
    
    **Tessellation曲面细分着色器**(完全可编程，可选)：细分图元，由 Hull shader、Tessellator、Domain shader 组成，借助曲面细分可以实现 LOD 机制。
    
    <img src=/images/pipeline-summary/Untitled%201.png width="60%" height="60%">
    
    
    **Geometry几何着色器**(完全可编程)：输入单个顶点的属性，输出经过变换之后的顶点。与定点着色器的区别是输入是完整的图元，输出可以是其他类型的图元，比如模型表面的法线可视化，就可以利用几何着色器实现。
    
    **Geometry Shader** 将法线可视化的例子
      
    输入图元为三角形，输出图元为三角形三个顶点的法线线段
      
      ```c
      layout (triangles) in;
      layout (line_strip, max_vertices = 6) out;
      ```
    <img src=/images/pipeline-summary/Untitled%202.png width="60%" height="60%">
    
    **Primitive Setup 图元装配**：将顶点组装成指定类型的图元，会进行**裁剪**和**背面剔除**的优化，以减少进入光栅化图元的数量。对落在视锥边缘的图元进行裁剪，对背朝相机的图元进行剔除，背面剔除默认关闭，可以通过`glEnable(GL_CULL_FACE)`控制，也可以设置剔除正面还是反面。判断正面还是背面可以通过图元顶点的绕向来确定。
  
    <img src=/images/pipeline-summary/Screen_Shot_2022-08-29_at_01.21.27.png width="75%" height="75%">
    
    **屏幕映射**(不可编程但可配置)：将每个图元转换到屏幕空间，在光栅化之前进行透视除法，将裁剪空间坐标转换到NDC：`device.xyz = gl_Position.xyz / gl_Position.w`
    
    然后得到片元的坐标：`gl_FragCoord.xyz = device.xyz scaled to viewport`这一步是NDC的坐标根据屏幕尺寸放缩到屏幕空间坐标，同时将`gl_FragCoord`的w分量：
    `gl_FragCoord.w = 1 / gl_Position.w`，这样做是为了后面的透视矫正插值
    
- 光栅化阶段：
    
    <img src=/images/pipeline-summary/Screen_Shot_2022-08-28_at_23.23.43.png width="50%" height="50%">
    
    经过屏幕映射之后，物体坐标转换为窗口坐标，经过光栅化离散成片元
    
    **三角形设置&遍历**(不可编程)：输入为三角形的三个顶点，**三角形设置**的任务是得到三角形边界的表示，然后**遍历**会检查每个像素是否被三角形网格覆盖(Overlap)，若覆盖则生成一个片元，最简单的 Point sampling 采样像素点的中心，除此之外还有用于抗锯齿的**超采样SSAA、多重采样MSAA**得到的片元包含了颜色、法线、纹理坐标、深度等属性，他们都是由三角形的顶点插值得到的，如果是透视投影，需要透视矫正插值得到正确的片元属性。（early-z 可以将深度测试提前到这里）
    
    **片元着色器**(完全可编程)：逐片元着色，片元着色器也是只影响单个片元，但是它可以访问导数信息(mipmap的基础)
    
    **输出合并阶段**(不可编程但可配置)：也可以叫测试混合阶段(包括裁剪测试、Alpha测试、模板测试、再深度测试)，决定每个片元的可见性，将通过测试的片元与已经在colorBuffer的颜色进行合并。这里注意Alpha测试的顺序是在深度测试之前，因为深度测试伴随着深度缓冲区的写入，如果一个片元先通过了深度测试，而在Alpha测试时被discard掉了，那已经写入的深度需要回滚，这样就比较 stupid。
    
    值得注意的是，半透明的物体需要从远到近依次绘制才能得到正确的颜色。一般在渲染透明物体时，会采用顺序无关的半透明渲染技术 (Order-Independent Transparency)
    

图像真正出现在屏幕上，还要经过 double buffering 的策略才能使图像连续地呈现出来。

## 剔除和裁剪

<img src=/images/pipeline-summary/Untitled%203.png width="85%" height="85%">

- 视椎体剔除 culling：应用程序阶段由CPU判断 object 的 AABB 在不在视锥内部并且与六个面相交，从而过滤掉完全处于视锥之外的物体，它们不用发送给几何处理阶段。
- 裁剪 clipping：物体 A 与视锥的面相交，针对这些 Object，需要将其在视锥内的三角形裁剪出来，而且可能将一个三角形切割成多个三角形，属于 Primitive 层面的处理。

## Early-z 和 Z-Prepass

- Early-Z

将原本 per-fragment 进行的 stencil-test、depth-test 提前到光栅化之后，没有通过测试的片元直接 discard 掉

![Untitled](images/pipeline-summary/Untitled%204.png)

但是有些情况下不能用 early-z：

- 开启Alpha Test 或 clip/discard 等手动丢弃片元操作
- Alpha Blend
- 手动修改GPU插值得到的深度

> OpenGL 里面会根据 shader 的代码自动判断需不需要 early-z，如果 fragment shader 需要输出z的值，early-z 会被禁用。
> 

- Z-Prepass

增加一个 Z-Prepass，其中只写入深度。

第二个 pass 中关闭深度写入，并将深度比较函数设置为相等。

## 透视投影和透视矫正插值

先回顾一下一个物体到最终展示在屏幕，都经过了哪些空间

![Screen Shot 2022-08-30 at 00.35.32.png](images/pipeline-summary/Screen_Shot_2022-08-30_at_00.35.32.png)

- 透视投影矩阵的推导：

参考 **[OpenGL Projection Matrix](http://www.songho.ca/opengl/gl_projectionmatrix.html)**

<img src=/images/pipeline-summary/Untitled%205.png width="80%" height="80%">

画出视锥内点e透视投影到近平面`z=-n`的点p，由三角形相似得到 $x_p$ 和 $y_p$ ：

<img src=/images/pipeline-summary/Untitled%206.png width="30%" height="30%">

<img src=/images/pipeline-summary/Untitled%207.png width="30%" height="30%">

注意到从视图空间到 NDC 经过的两次变换，结合 $x_p$ 和 $y_p$ 发现裁剪空间坐标的 w 分量 $w_{clip}=-z_e$

<img src=/images/pipeline-summary/Untitled%208.png width="40%" height="40%">

<img src=/images/pipeline-summary/Untitled%209.png width="30%" height="30%">

所以可以得到透视矩阵的第四行：

<img src=/images/pipeline-summary/Untitled%2010.png width="65%" height="65%">

下面代入两组边界点 [l, r] ⇒ [-1, 1] 和 [b, t] ⇒ [-1, 1]，可以得到变换的前两行：

<img src=/images/pipeline-summary/Untitled%2011.png width="45%" height="45%">

至此问题只剩下如何求变换的第三行，也就是 $z_e$ 应该取什么值？这个问题比较特殊，因为视锥中的点最终一定会投影到近平面上，貌似 $z_c$ 取什么值是没有意义的，但是我们可以借助 $z_c$ 来保留原来视图空间的深度 $z_e$ 

<img src=/images/pipeline-summary/Untitled%2012.png width="80%" height="80%">

这样我们就建立了 NDC 中的深度 $z_n$ 和视图空间深度  $z_e$ 的关系，待定的系数 $A$ 和  $B$ 可以代入两组边界的点求得，得到完整透视投影矩阵：

<img src=/images/pipeline-summary/Untitled%2013.png width="40%" height="40%">

- 透视矫正插值

在求三角形内某点 $x$ 的属性时，我们通过求得 $x$ 的重心坐标进行插值，重心坐标的系数是每个小三角形的面积与总的大三角形面积的比值，这样计算的好处是我们在判断点 $x$ 是否在三角形内，通过计算叉乘的符号来判断的，其实叉乘的值就是两倍的小三角形面积。

<img src=/images/pipeline-summary/Untitled%2014.png width="70%" height="70%">

然而 3D 的重心坐标和透视投影之后 2D 的重心坐标并不相等，所以屏幕空间的插值并不是线性插值，参考下面的几何示意图：

<img src=/images/pipeline-summary/Untitled%2015.png width="70%" height="70%">

如果没有进行透视矫正，得到的插值属性会有些奇怪，下面“Affine”图中可以看到不同三角形UV的变化率不同：

![Screen Shot 2022-08-30 at 01.36.15.png](images/pipeline-summary/Screen_Shot_2022-08-30_at_01.36.15.png)

透视矫正插值的具体步骤：
1. 得到每个顶点的深度 $z$
2. 将每个顶点需要插值的属性 $p$ 写成   $P = p/z$
3. 在2D的屏幕空间对 $P$ 进行重心坐标的插值
4. 再将 $P$ 还原回 $p$ 得到正确的的属性值 

[**Perspective-Correct Interpolation**](https://www.comp.nus.edu.sg/~lowkl/publications/lowk_persp_interp_techrep.pdf)：这篇文章讲了用 $1/z$ 做插值的详细推导。

还记得前面的透视投影矩阵和透视除法得到的 NDC 中的深度 $z_n$ 其实已经除过  $z_e$ 了，所以深度 $z_n$ 可以直接用屏幕空间的重心坐标线性插值，但是其他的属性，比如颜色、UV，都要先经过步骤2的处理才能用屏幕空间的重心坐标插值。

<img src=/images/pipeline-summary/Untitled%2016.png width="40%" height="40%">

OpenGL中顶点着色器将顶点经过MVP变换到裁剪空间后，在光栅化之前的屏幕映射阶段会进行两步操作

```c
// 裁剪空间的坐标进行透视除法，得到NDC坐标，这个w其实就是z_e 
device.xyz = gl_Position.xyz / gl_Position.w;

// NDC坐标转换为屏幕空间的坐标，同时w分量变成1/z，为了方便逐片元计算透视矫正插值的属性
gl_FragCoord.xyz = ScaledToViewport(device.xyz);
gl_FragCoord.w = 1 / gl_Position.w;
```

# Render Pipeline

## Forward

内循环主体是 light 的方式叫做 single-pass lighting，与之对应的是 multi-pass lighting

```cpp
for mesh in meshes:
	for light in lights:
		draw(mesh, light)
```

透明物体：

```cpp
for light in lights:
	for mesh in opaqueMeshes:
		draw(mesh, light)
	for mesh in transparentMeshes:
		draw(mesh, light)
```

- 优点：光源少的时候优势明显，比较好处理透明物体，可以对不同的mesh应用不同的材质。
- 缺点及优化：整个场景的光照计算复杂度为 Mesh x Lights。需要针对性优化，比如 Multi-Pass Lighting 中可以设置每个光源影响的物体列表。通过剔除来降低 Overdraw，比如使用大物件的HZB，以及对动态物体使用 depth-only 提前绘制一遍的 Early-Z 剔除算法。

## Deferred

Deferred Rendering 可以概括为两个 Pass：
1. Geometry Pass，完成物体的几何数据处理，将光照计算所需要的数据写入到 GBuffer
2. Lighting Pass，通过一个后处理对每盏光源所覆盖的像素进行 shading，写入 FrameBuffer 

![Untitled](images/pipeline-summary/Untitled%2017.png)

延迟渲染中解耦了光源和mesh的作用

```cpp
for mesh in meshes:
	drawToGBuffer(mesh)
for light in lights:
	drawToFrameBuffer(light)
```

- 优点：
  - 解决了 Forward Rendering 在多光源效率低下的问题。极大降低了 Forward Rendering 中的 Overdraw
- 缺点：
  - G-Buffer 要求更多的存储空间，材质越多会加重 G-Buffer的大小
  - 无法处理透明物体，需要额外的Pass
  - 不好实现 [MSAA](https://zhuanlan.zhihu.com/p/135444145)，需要 G-Buffer 开相应的倍数
  - 只能支持单一的 Lighting Model

## Deferred-Rendering with Transparent Objects

[GTA V - Graphics Study - Adrian Courrèges](http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/)

## Why Forward Again?

> Doom Eternal is using a Forward Rendering pipeline. 

Why？他们用了很多先进的pre-processing来处理光照、和物体，尽可能剔除掉不需要shading的部分，这样就大大降低了cpu和gpu之间的数据传输量。随着硬件的发展，drawcall的成本越来越小，gpu和cpu之间传数据逐渐成为新的 botttle neck。(其实不只有gpu和cpu之间的传输，在gpu内部也会频繁发生数据传输)

[DOOM Eternal - Graphics Study](https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html)
[DOOM Eternal Tested on Low-end Graphics Cards](https://www.techspot.com/article/2001-doom-eternal-older-gpu-test/)

## Tile-Based Deferred Rendering

由于Deferred Shading 中的 G-Buffer 要求比较高的带宽，而移动端上带宽资源有限，Tile-Based Deferred Rendering 就是针对移动端设计的分块 Deferred Rendering。
其思想是将屏幕划分成子区域，分块渲染，这样在每一小块上的带宽不高，可以解决带宽的限制。听起来好像没有什么特别之处，但这个方案在实际应用中很快成为移动端硬件的标配。

## Forward+
也叫 Tiled Forward Rendering，可以概括为三个 Pass：
1. Depth Pass
    获取屏幕空间的 Depth 数据，为了后面逐 Tile 的 Light Culling，也是为了减少后面 Geometry Shading Pass 的 Overdraw
2. Lighting Cull Pass
    Forward Rendering 慢的原因就是每个片元都要考虑每盏灯光的影响，所以这里将灯光影响的像素范围进行计算。将屏幕空间分成 Tile，进行 Light Culling。根据 Tile Size 以及上一步获取到的 Depth Buffer，获取每个 Tile 的 Depth Extent，并根据每个 Tile 的 Sub Frustum 与 Light 的作用范围计算出影响到当前 Tile 的 Light List，整个过程可以通过 Compute Shader 完成（有Scatter跟Gather两种实现方案）
3. Geometry Shading Pass
    普通的 Forward Pass，每个片元着色的时候只与所在 Tile 相关的 Light List 进行光照计算。
    

# Reference

1. **[常见渲染管线整理与总结 - 简书 by离原春草](https://www.jianshu.com/p/6b5c9035b361)**
2. **[Shader学习 （20）延迟渲染和前向渲染](https://www.ai2news.com/blog/1444791/)**
3. **[Forward Rendering vs. Deferred Rendering](https://gamedevelopment.tutsplus.com/articles/forward-rendering-vs-deferred-rendering--gamedev-12342)**
4. **[Forward and Deferred Rendering](https://www.youtube.com/watch?v=n5OiqJP2f7w)**
5. **[Deferred Shading in *S.T.A.L.K.E.R.*](https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-9-deferred-shading-stalker)**
6. **[The Early History of Deferred Shading and Lighting](https://sites.google.com/site/richgel99/the-early-history-of-deferred-shading-and-lighting)**
7. **[Tutorial 05 - Implementing Deferred Rendering](https://www.youtube.com/watch?v=BYo9xaU1sZg)**
8. **[DOOM Eternal Tested on Low-end Graphics Cards](https://www.techspot.com/article/2001-doom-eternal-older-gpu-test/)**
9. **[Forward-Plus-Renderer](https://github.com/bcrusco/Forward-Plus-Renderer)**
10. **[Introduction to Forward+ rendering - geometry pass | C++ Game Engine](https://www.youtube.com/watch?v=a9trwl4fEQs)**
